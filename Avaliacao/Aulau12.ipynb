{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "#imports\n",
    "from src.si.data import dataset\n",
    "from si.io.csv import read_csv\n",
    "from src.si.neuronal_networks.nn import NN\n",
    "from src.si.neuronal_networks.layer import Dense\n",
    "from src.si.neuronal_networks.layer import SigmoidActivation\n",
    "from src.si.neuronal_networks.layer import SoftMaxActivation\n",
    "from src.si.neuronal_networks.layer import ReLUActivation\n",
    "from src.si.metrics.cross_entropy import cross_entropy\n",
    "from src.si.metrics.cross_entropy import cross_entropy_derivative\n",
    "from src.si.linear_model.ridge_regression import RidgeRegression\n",
    "from src.si.linear_model.logistic_regression import LogisticRegression\n",
    "from src.si.model_selection.split import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from src.si.io.csv import read_csv\n",
    "from sklearn.preprocessing import StandardScaler"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 9)\n",
      "(279, 9)\n"
     ]
    }
   ],
   "source": [
    "#Constrói um modelo de redes neuronais adequado ao dataset breast bin.csv\n",
    "breast_dataset = read_csv('../datasets/breast-bin.csv', features=False, label=True)\n",
    "breast_dataset.X = StandardScaler().fit_transform(breast_dataset.X)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(breast_dataset, test_size=0.4)\n",
    "print(train_dataset.shape())\n",
    "print(test_dataset.shape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "layer1 = Dense(input_size=9, output_size=9)\n",
    "layer2 = Dense(input_size=9, output_size=5)\n",
    "layer3 = Dense(input_size=5, output_size=1)\n",
    "\n",
    "layer1_act = ReLUActivation()\n",
    "layer2_act = ReLUActivation()\n",
    "layer3_act = SigmoidActivation()\n",
    "\n",
    "model_breast = NN(\n",
    "    layers=[layer1, layer1_act, layer2, layer2_act, layer3, layer3_act], loss=cross_entropy, loss_derivative=cross_entropy_derivative, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (419,419) and (1,5) not aligned: 419 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-8-b7e1f35f6413>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodel_breast\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\SIB\\src\\si\\neuronal_networks\\nn.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m     93\u001B[0m             \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_derivative\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 95\u001B[1;33m                 \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlearning_rate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     96\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m             \u001B[1;31m# save history\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\SIB\\src\\si\\neuronal_networks\\layer.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, error, learning_rate)\u001B[0m\n\u001B[0;32m     67\u001B[0m             \u001B[0mThe\u001B[0m \u001B[0merror\u001B[0m \u001B[0mof\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mprevious\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     68\u001B[0m         \"\"\"\n\u001B[1;32m---> 69\u001B[1;33m         \u001B[0merror_to_propagate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweights\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     70\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mweights\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[0mlearning_rate\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0merror\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     71\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbias\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[0mlearning_rate\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mdot\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: shapes (419,419) and (1,5) not aligned: 419 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "model_breast.fit(dataset= train_dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.4999981 ],\n       [0.4999995 ],\n       [0.49999971],\n       [0.50000119],\n       [0.49999983],\n       [0.5       ],\n       [0.50000484],\n       [0.49999896],\n       [0.49999788],\n       [0.50000175],\n       [0.50000021],\n       [0.49999901],\n       [0.49999797],\n       [0.49999848],\n       [0.5000003 ],\n       [0.50000076],\n       [0.50000009],\n       [0.49999657],\n       [0.49999989],\n       [0.50000021],\n       [0.49999948],\n       [0.49999838],\n       [0.50000265],\n       [0.50000031],\n       [0.50000316],\n       [0.50000015],\n       [0.49999782],\n       [0.50000122],\n       [0.4999998 ],\n       [0.5000001 ],\n       [0.49999915],\n       [0.49999863],\n       [0.49999782],\n       [0.50000594],\n       [0.49999926],\n       [0.49999896],\n       [0.49999755],\n       [0.49999794],\n       [0.50000021],\n       [0.50000016],\n       [0.49999843],\n       [0.5000001 ],\n       [0.50000039],\n       [0.50000371],\n       [0.50000088],\n       [0.49999879],\n       [0.50000365],\n       [0.49999854],\n       [0.49999856],\n       [0.49999969],\n       [0.49999894],\n       [0.50000021],\n       [0.50000216],\n       [0.5       ],\n       [0.49999894],\n       [0.49999898],\n       [0.50000068],\n       [0.50000009],\n       [0.50000351],\n       [0.49999989],\n       [0.49999968],\n       [0.50000021],\n       [0.49999905],\n       [0.5       ],\n       [0.4999995 ],\n       [0.49999925],\n       [0.49999948],\n       [0.50000187],\n       [0.50000167],\n       [0.5       ],\n       [0.50000177],\n       [0.5000001 ],\n       [0.50000157],\n       [0.50000175],\n       [0.49999789],\n       [0.5       ],\n       [0.4999995 ],\n       [0.49999878],\n       [0.5000001 ],\n       [0.4999995 ],\n       [0.5       ],\n       [0.50000491],\n       [0.49999855],\n       [0.50000156],\n       [0.50000256],\n       [0.50000002],\n       [0.50000181],\n       [0.50000186],\n       [0.50000347],\n       [0.49999969],\n       [0.50000209],\n       [0.50000292],\n       [0.49999948],\n       [0.50000194],\n       [0.49999978],\n       [0.5000001 ],\n       [0.49999969],\n       [0.50000109],\n       [0.50000021],\n       [0.5       ],\n       [0.49999727],\n       [0.50000114],\n       [0.49999856],\n       [0.49999856],\n       [0.49999739],\n       [0.50000294],\n       [0.50000021],\n       [0.50000282],\n       [0.49999989],\n       [0.5000001 ],\n       [0.49999832],\n       [0.5       ],\n       [0.49999772],\n       [0.4999995 ],\n       [0.49999885],\n       [0.50000365],\n       [0.50000107],\n       [0.50000134],\n       [0.49999896],\n       [0.49999886],\n       [0.50000148],\n       [0.49999915],\n       [0.50000247],\n       [0.5       ],\n       [0.49999816],\n       [0.49999937],\n       [0.49999896],\n       [0.49999912],\n       [0.49999816],\n       [0.50000249],\n       [0.49999784],\n       [0.49999891],\n       [0.50000011],\n       [0.49999671],\n       [0.49999923],\n       [0.50000021],\n       [0.49999824],\n       [0.49999915],\n       [0.49999838],\n       [0.49999777],\n       [0.49999998],\n       [0.49999968],\n       [0.5000018 ],\n       [0.49999928],\n       [0.50000224],\n       [0.49999872],\n       [0.50000494],\n       [0.49999968],\n       [0.50000021],\n       [0.49999936],\n       [0.49999947],\n       [0.49999863],\n       [0.49999925],\n       [0.49999855],\n       [0.50000085],\n       [0.49999935],\n       [0.50000272],\n       [0.50000215],\n       [0.49999815],\n       [0.49999948],\n       [0.50000591],\n       [0.50000041],\n       [0.50000435],\n       [0.50000021],\n       [0.5       ],\n       [0.49999902],\n       [0.49999864],\n       [0.50000278],\n       [0.49999838],\n       [0.49999734],\n       [0.49999904],\n       [0.49999886],\n       [0.5000043 ],\n       [0.50000417],\n       [0.49999896],\n       [0.50000272],\n       [0.5000001 ],\n       [0.50000345],\n       [0.5       ],\n       [0.50000502],\n       [0.49999996],\n       [0.50000089],\n       [0.4999978 ],\n       [0.5000019 ],\n       [0.49999746],\n       [0.49999874],\n       [0.50000026],\n       [0.49999896],\n       [0.5000003 ],\n       [0.50000053],\n       [0.49999894],\n       [0.49999736],\n       [0.50000042],\n       [0.50000021],\n       [0.49999896],\n       [0.50000077],\n       [0.49999878],\n       [0.50000469],\n       [0.49999988],\n       [0.49999714],\n       [0.49999806],\n       [0.49999896],\n       [0.50000236],\n       [0.49999951],\n       [0.49999894],\n       [0.49999985],\n       [0.5       ],\n       [0.5000001 ],\n       [0.49999938],\n       [0.50000059],\n       [0.49999763],\n       [0.50000351],\n       [0.50000216],\n       [0.49999655],\n       [0.49999831],\n       [0.49999861],\n       [0.49999896],\n       [0.4999995 ],\n       [0.49999782],\n       [0.49999989],\n       [0.49999831],\n       [0.49999957],\n       [0.49999732],\n       [0.50000015],\n       [0.50000104],\n       [0.49999965],\n       [0.49999774],\n       [0.49999861],\n       [0.50000041],\n       [0.49999915],\n       [0.49999819],\n       [0.50000029],\n       [0.49999988],\n       [0.5000001 ],\n       [0.49999953],\n       [0.49999818],\n       [0.49999941],\n       [0.50000055],\n       [0.49999896],\n       [0.50000217],\n       [0.49999754],\n       [0.49999989],\n       [0.4999981 ],\n       [0.5000001 ],\n       [0.50000106],\n       [0.49999906],\n       [0.50000271],\n       [0.50000021],\n       [0.5000001 ],\n       [0.50000362],\n       [0.50000041],\n       [0.50000009],\n       [0.50000387],\n       [0.50000217],\n       [0.49999784],\n       [0.49999784],\n       [0.50000262],\n       [0.49999851],\n       [0.50000116],\n       [0.49999865],\n       [0.49999868],\n       [0.49999915],\n       [0.50000289],\n       [0.49999971],\n       [0.50000633],\n       [0.50000176],\n       [0.49999915],\n       [0.4999991 ],\n       [0.50000089],\n       [0.50000021],\n       [0.50000027],\n       [0.49999957],\n       [0.49999838],\n       [0.49999825],\n       [0.49999944],\n       [0.49999989],\n       [0.49999777],\n       [0.49999744],\n       [0.49999726],\n       [0.50000353],\n       [0.5000006 ],\n       [0.49999797],\n       [0.49999784],\n       [0.50000463],\n       [0.49999958],\n       [0.49999777],\n       [0.49999822],\n       [0.49999812],\n       [0.49999838],\n       [0.50000389],\n       [0.50000103],\n       [0.50000217],\n       [0.49999896],\n       [0.5000001 ],\n       [0.49999797],\n       [0.49999915],\n       [0.50000362],\n       [0.49999942],\n       [0.49999848],\n       [0.50000287],\n       [0.50000028],\n       [0.50000388],\n       [0.4999985 ],\n       [0.49999915],\n       [0.50000241],\n       [0.5000001 ],\n       [0.49999698],\n       [0.49999894],\n       [0.50000048],\n       [0.49999856],\n       [0.49999843],\n       [0.50000723],\n       [0.49999856],\n       [0.5000007 ],\n       [0.49999999],\n       [0.49999824],\n       [0.4999985 ],\n       [0.5000032 ],\n       [0.49999739],\n       [0.49999856],\n       [0.49999981],\n       [0.49999762],\n       [0.50000217],\n       [0.50000057],\n       [0.50000173],\n       [0.49999948],\n       [0.50000367],\n       [0.49999843],\n       [0.50000021],\n       [0.50000307],\n       [0.49999693],\n       [0.49999863],\n       [0.5       ],\n       [0.50000318],\n       [0.49999777],\n       [0.49999863],\n       [0.49999675],\n       [0.50000044],\n       [0.50000021],\n       [0.50000118],\n       [0.5       ],\n       [0.49999838],\n       [0.49999985],\n       [0.50000021],\n       [0.49999805],\n       [0.50000226],\n       [0.50000077],\n       [0.49999784],\n       [0.49999782],\n       [0.5000011 ],\n       [0.49999784],\n       [0.50000108],\n       [0.49999861],\n       [0.50000153],\n       [0.49999981],\n       [0.49999789],\n       [0.49999792],\n       [0.49999916],\n       [0.49999856],\n       [0.50000392],\n       [0.49999915],\n       [0.49999968],\n       [0.5       ],\n       [0.50000166],\n       [0.50000388],\n       [0.50000438],\n       [0.49999816],\n       [0.49999935],\n       [0.49999547],\n       [0.5       ],\n       [0.49999904],\n       [0.5000028 ],\n       [0.49999863],\n       [0.50000364],\n       [0.5       ],\n       [0.49999754],\n       [0.49999938],\n       [0.50000158],\n       [0.50000194],\n       [0.49999861],\n       [0.50000056],\n       [0.49999915],\n       [0.50000218],\n       [0.5       ],\n       [0.49999915],\n       [0.50000382],\n       [0.49999843],\n       [0.50000202],\n       [0.49999976],\n       [0.49999838],\n       [0.4999995 ],\n       [0.49999797],\n       [0.5       ],\n       [0.49999863],\n       [0.5000001 ],\n       [0.50000021],\n       [0.50000086],\n       [0.49999843],\n       [0.49999896],\n       [0.5000001 ],\n       [0.50000226],\n       [0.50000329],\n       [0.50000012],\n       [0.5000036 ],\n       [0.49999894],\n       [0.49999969],\n       [0.50000498],\n       [0.49999843],\n       [0.50000121],\n       [0.5       ],\n       [0.5000001 ],\n       [0.49999784],\n       [0.50000148],\n       [0.49999896],\n       [0.49999942],\n       [0.49999721],\n       [0.50000027],\n       [0.49999845],\n       [0.49999979]])"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_breast.predict(dataset= train_dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 6)\n",
      "(83, 6)\n"
     ]
    }
   ],
   "source": [
    "#Constrói um modelo de redes neuronais adequado ao dataset cpu.csv\n",
    "cpu_dataset = read_csv('../datasets/cpu.csv', features=True, label=True)\n",
    "cpu_dataset.X = StandardScaler().fit_transform(cpu_dataset.X)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(cpu_dataset, test_size=0.4)\n",
    "print(train_dataset.shape())\n",
    "print(test_dataset.shape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "layer1 = Dense(input_size=6, output_size=6)\n",
    "layer2 = Dense(input_size=6, output_size=4)\n",
    "layer3 = Dense(input_size=4, output_size=1)\n",
    "\n",
    "layer1_act = ReLUActivation()\n",
    "layer2_act = ReLUActivation()\n",
    "layer3_act = SigmoidActivation()\n",
    "\n",
    "model_cpu = NN(\n",
    "    layers=[layer1, layer1_act, layer2, layer2_act, layer3, layer3_act], loss=cross_entropy, loss_derivative=cross_entropy_derivative, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "backward() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-44-2a00b4b928a4>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodel_cpu\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdataset\u001B[0m\u001B[1;33m=\u001B[0m \u001B[0mtrain_dataset\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\SIB\\src\\si\\neuronal_networks\\nn.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, dataset)\u001B[0m\n\u001B[0;32m     93\u001B[0m             \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloss_derivative\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     94\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mlayer\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 95\u001B[1;33m                 \u001B[0merror\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0merror\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mlearning_rate\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     96\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m             \u001B[1;31m# save history\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: backward() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "model_cpu.fit(dataset= train_dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.50000002],\n       [0.50000006],\n       [0.50000019],\n       [0.50000259],\n       [0.5       ],\n       [0.50000003],\n       [0.50000097],\n       [0.5       ],\n       [0.5       ],\n       [0.50000011],\n       [0.5       ],\n       [0.50000006],\n       [0.5       ],\n       [0.5       ],\n       [0.50000112],\n       [0.5       ],\n       [0.5       ],\n       [0.50000127],\n       [0.49999927],\n       [0.50000012],\n       [0.5       ],\n       [0.49999868],\n       [0.49999761],\n       [0.50000002],\n       [0.5       ],\n       [0.5       ],\n       [0.50000004],\n       [0.4999992 ],\n       [0.49999927],\n       [0.5       ],\n       [0.49999975],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000011],\n       [0.5       ],\n       [0.49999984],\n       [0.49999819],\n       [0.5       ],\n       [0.50000052],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000019],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000261],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000106],\n       [0.49999902],\n       [0.5       ],\n       [0.5       ],\n       [0.50000007],\n       [0.5       ],\n       [0.50000016],\n       [0.5       ],\n       [0.50000003],\n       [0.49999896],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.4999992 ],\n       [0.49999761],\n       [0.50000129],\n       [0.50000011],\n       [0.5       ],\n       [0.5       ],\n       [0.49999937],\n       [0.50000005],\n       [0.5       ],\n       [0.5000001 ],\n       [0.50000112],\n       [0.50000005],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000003],\n       [0.49999725],\n       [0.50000021],\n       [0.50000004],\n       [0.50000117],\n       [0.50000087],\n       [0.5       ],\n       [0.50000005],\n       [0.49999951],\n       [0.50000112],\n       [0.50000004],\n       [0.50000014],\n       [0.5       ],\n       [0.50000112],\n       [0.5       ],\n       [0.5       ],\n       [0.50000002],\n       [0.5       ],\n       [0.5       ],\n       [0.49999484],\n       [0.5       ],\n       [0.50000004],\n       [0.5       ],\n       [0.49999999],\n       [0.49999978],\n       [0.50000167],\n       [0.50000015],\n       [0.50000005],\n       [0.5       ],\n       [0.5       ],\n       [0.49999989],\n       [0.50000027],\n       [0.5       ],\n       [0.49999993],\n       [0.5       ],\n       [0.50000025],\n       [0.50000001],\n       [0.5       ],\n       [0.5       ],\n       [0.50000165]])"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cpu.predict(dataset= train_dataset)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e79b8fed",
   "language": "python",
   "display_name": "PyCharm (sonia)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}