{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "from src.si.data import dataset\n",
    "from si.io.csv import read_csv\n",
    "from src.si.neuronal_networks.nn import NN\n",
    "from src.si.neuronal_networks.layer import Dense\n",
    "from src.si.neuronal_networks.layer import SigmoidActivation\n",
    "from src.si.neuronal_networks.layer import SoftMaxActivation\n",
    "from src.si.neuronal_networks.layer import ReLUActivation\n",
    "from src.si.metrics.cross_entropy import cross_entropy\n",
    "from src.si.metrics.cross_entropy import cross_entropy_derivative\n",
    "from src.si.linear_model.ridge_regression import RidgeRegression\n",
    "from src.si.linear_model.logistic_regression import LogisticRegression\n",
    "from src.si.model_selection.split import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from src.si.io.csv import read_csv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(419, 9)\n",
      "(279, 9)\n"
     ]
    }
   ],
   "source": [
    "#Constr√≥i um modelo de redes neuronais adequado ao dataset breast bin.csv\n",
    "breast_dataset = read_csv('../datasets/breast-bin.csv', features=False, label=True)\n",
    "breast_dataset.X = StandardScaler().fit_transform(breast_dataset.X)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(breast_dataset, test_size=0.4)\n",
    "print(train_dataset.shape())\n",
    "print(test_dataset.shape())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "layer1 = Dense(input_size=9, output_size=9)\n",
    "layer2 = Dense(input_size=9, output_size=5)\n",
    "layer3 = Dense(input_size=5, output_size=1)\n",
    "\n",
    "layer1_act = ReLUActivation()\n",
    "layer2_act = ReLUActivation()\n",
    "layer3_act = SigmoidActivation()\n",
    "\n",
    "model_breast = NN(\n",
    "    layers=[layer1, layer1_act, layer2, layer2_act, layer3, layer3_act], loss=cross_entropy, loss_derivative=cross_entropy_derivative, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_breast.fit(dataset= train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.50000005],\n       [0.50000016],\n       [0.49999182],\n       [0.49999225],\n       [0.4999988 ],\n       [0.50000015],\n       [0.49998918],\n       [0.50000012],\n       [0.49999966],\n       [0.49999071],\n       [0.50000019],\n       [0.49999992],\n       [0.49999987],\n       [0.5       ],\n       [0.50000022],\n       [0.4999904 ],\n       [0.50000013],\n       [0.49998222],\n       [0.49999174],\n       [0.50000019],\n       [0.50000014],\n       [0.50000012],\n       [0.5000001 ],\n       [0.49999265],\n       [0.49999419],\n       [0.49999913],\n       [0.50000011],\n       [0.49998984],\n       [0.49999958],\n       [0.50000014],\n       [0.50000008],\n       [0.50000008],\n       [0.50000011],\n       [0.49998863],\n       [0.49998533],\n       [0.50000008],\n       [0.49999005],\n       [0.49998866],\n       [0.50000019],\n       [0.50000019],\n       [0.5000001 ],\n       [0.50000014],\n       [0.49999952],\n       [0.49998532],\n       [0.50000023],\n       [0.49999896],\n       [0.49998899],\n       [0.49999949],\n       [0.50000002],\n       [0.50000012],\n       [0.50000014],\n       [0.50000019],\n       [0.49999494],\n       [0.50000015],\n       [0.50000014],\n       [0.49999015],\n       [0.49998966],\n       [0.50000013],\n       [0.49998994],\n       [0.50000011],\n       [0.49999999],\n       [0.50000019],\n       [0.5000001 ],\n       [0.50000015],\n       [0.50000016],\n       [0.50000012],\n       [0.50000014],\n       [0.49998887],\n       [0.49999821],\n       [0.50000015],\n       [0.50000033],\n       [0.50000014],\n       [0.49999329],\n       [0.49999868],\n       [0.50000001],\n       [0.50000015],\n       [0.50000016],\n       [0.49999928],\n       [0.50000014],\n       [0.50000016],\n       [0.50000015],\n       [0.49999641],\n       [0.49999088],\n       [0.49999159],\n       [0.49999433],\n       [0.49999988],\n       [0.49999259],\n       [0.4999888 ],\n       [0.49998698],\n       [0.50000012],\n       [0.49999266],\n       [0.49998943],\n       [0.50000014],\n       [0.49999804],\n       [0.49998574],\n       [0.50000014],\n       [0.50000012],\n       [0.49999182],\n       [0.50000019],\n       [0.50000015],\n       [0.49999923],\n       [0.49999578],\n       [0.49999877],\n       [0.50000002],\n       [0.49999962],\n       [0.49999717],\n       [0.50000019],\n       [0.500001  ],\n       [0.50000011],\n       [0.50000014],\n       [0.5000001 ],\n       [0.49999961],\n       [0.49998942],\n       [0.50000016],\n       [0.50000017],\n       [0.49999008],\n       [0.49999374],\n       [0.49999095],\n       [0.50000012],\n       [0.49999968],\n       [0.49999723],\n       [0.50000008],\n       [0.50000015],\n       [0.50000015],\n       [0.49999955],\n       [0.50000019],\n       [0.50000012],\n       [0.4999987 ],\n       [0.49999955],\n       [0.50000054],\n       [0.50000006],\n       [0.49999966],\n       [0.50000057],\n       [0.49999724],\n       [0.49998976],\n       [0.50000019],\n       [0.49999993],\n       [0.50000008],\n       [0.50000012],\n       [0.50000008],\n       [0.49998526],\n       [0.49999999],\n       [0.49999031],\n       [0.50000008],\n       [0.49999782],\n       [0.50000011],\n       [0.49999603],\n       [0.49999999],\n       [0.4999947 ],\n       [0.50000008],\n       [0.49999898],\n       [0.49999998],\n       [0.50000012],\n       [0.49999993],\n       [0.50000016],\n       [0.4999913 ],\n       [0.49999512],\n       [0.49998253],\n       [0.49999925],\n       [0.50000014],\n       [0.49998806],\n       [0.50000005],\n       [0.49998804],\n       [0.50000019],\n       [0.50000015],\n       [0.49999045],\n       [0.49999325],\n       [0.4999908 ],\n       [0.50000012],\n       [0.50000005],\n       [0.50000006],\n       [0.49999968],\n       [0.49999299],\n       [0.49999239],\n       [0.50000012],\n       [0.49999512],\n       [0.50000014],\n       [0.4999932 ],\n       [0.50000015],\n       [0.49999173],\n       [0.49999113],\n       [0.49999134],\n       [0.49999588],\n       [0.49999357],\n       [0.49999025],\n       [0.50000005],\n       [0.49999838],\n       [0.50000012],\n       [0.50000003],\n       [0.49999118],\n       [0.50000014],\n       [0.49998732],\n       [0.50000017],\n       [0.50000019],\n       [0.50000012],\n       [0.49998763],\n       [0.49999931],\n       [0.49998888],\n       [0.49999976],\n       [0.49999296],\n       [0.50000005],\n       [0.50000012],\n       [0.50000013],\n       [0.49998725],\n       [0.50000014],\n       [0.49999589],\n       [0.50000015],\n       [0.50000014],\n       [0.49999486],\n       [0.50000093],\n       [0.49999972],\n       [0.49999424],\n       [0.49999701],\n       [0.49998553],\n       [0.4999999 ],\n       [0.50000007],\n       [0.50000012],\n       [0.50000016],\n       [0.50000011],\n       [0.50000018],\n       [0.4999999 ],\n       [0.4999999 ],\n       [0.49998523],\n       [0.49999913],\n       [0.50000249],\n       [0.50000022],\n       [0.49999982],\n       [0.49999939],\n       [0.50000005],\n       [0.50000008],\n       [0.50000002],\n       [0.4999923 ],\n       [0.50000009],\n       [0.50000014],\n       [0.50000013],\n       [0.50000001],\n       [0.49999913],\n       [0.49999993],\n       [0.50000012],\n       [0.49998468],\n       [0.49999926],\n       [0.50000011],\n       [0.50000005],\n       [0.50000014],\n       [0.4999911 ],\n       [0.50000004],\n       [0.49998287],\n       [0.50000019],\n       [0.50000014],\n       [0.49998729],\n       [0.49999966],\n       [0.50000013],\n       [0.50000325],\n       [0.49999599],\n       [0.50000006],\n       [0.50000006],\n       [0.49999461],\n       [0.49999933],\n       [0.49999202],\n       [0.49999999],\n       [0.49999864],\n       [0.50000008],\n       [0.49999474],\n       [0.50000002],\n       [0.49999282],\n       [0.49999874],\n       [0.50000008],\n       [0.49999823],\n       [0.49999665],\n       [0.50000019],\n       [0.50000011],\n       [0.4999999 ],\n       [0.50000012],\n       [0.49999987],\n       [0.49999319],\n       [0.50000011],\n       [0.50000008],\n       [0.49999728],\n       [0.49999027],\n       [0.50000056],\n       [0.49999009],\n       [0.49999987],\n       [0.50000006],\n       [0.49999251],\n       [0.50000007],\n       [0.49999936],\n       [0.49999986],\n       [0.49998806],\n       [0.50000012],\n       [0.49999958],\n       [0.49999925],\n       [0.49998946],\n       [0.50000012],\n       [0.50000014],\n       [0.49999987],\n       [0.50000008],\n       [0.49999924],\n       [0.49999964],\n       [0.49999945],\n       [0.4999896 ],\n       [0.49999259],\n       [0.49999159],\n       [0.49999966],\n       [0.50000008],\n       [0.49999868],\n       [0.50000014],\n       [0.5000007 ],\n       [0.50000014],\n       [0.5000001 ],\n       [0.50000002],\n       [0.5000001 ],\n       [0.49998261],\n       [0.50000002],\n       [0.50000017],\n       [0.49999452],\n       [0.49999993],\n       [0.49999994],\n       [0.49999113],\n       [0.49999962],\n       [0.50000002],\n       [0.50000014],\n       [0.49999985],\n       [0.49999071],\n       [0.49999953],\n       [0.49999231],\n       [0.50000014],\n       [0.4999977 ],\n       [0.49999989],\n       [0.50000019],\n       [0.4999877 ],\n       [0.49999919],\n       [0.4999978 ],\n       [0.50000015],\n       [0.49999668],\n       [0.50000008],\n       [0.50000008],\n       [0.4999991 ],\n       [0.49999942],\n       [0.50000019],\n       [0.49999004],\n       [0.50000015],\n       [0.50000012],\n       [0.49998333],\n       [0.50000019],\n       [0.49999988],\n       [0.50000037],\n       [0.49998398],\n       [0.50000006],\n       [0.50000011],\n       [0.49998746],\n       [0.50000006],\n       [0.49999071],\n       [0.50000007],\n       [0.50000029],\n       [0.50000014],\n       [0.50000001],\n       [0.49999896],\n       [0.49999898],\n       [0.50000002],\n       [0.49999491],\n       [0.50000008],\n       [0.49999999],\n       [0.50000015],\n       [0.49999229],\n       [0.49998145],\n       [0.49999966],\n       [0.49999932],\n       [0.50000006],\n       [0.49998736],\n       [0.50000015],\n       [0.49999994],\n       [0.49999421],\n       [0.50000008],\n       [0.49999572],\n       [0.50000015],\n       [0.49999926],\n       [0.50000007],\n       [0.49999089],\n       [0.49998575],\n       [0.50000007],\n       [0.49998847],\n       [0.5000001 ],\n       [0.50000035],\n       [0.50000014],\n       [0.50000008],\n       [0.49998881],\n       [0.5000001 ],\n       [0.5000002 ],\n       [0.49999999],\n       [0.49999855],\n       [0.50000016],\n       [0.49999987],\n       [0.50000015],\n       [0.49999998],\n       [0.50000014],\n       [0.50000019],\n       [0.5000025 ],\n       [0.5000001 ],\n       [0.50000012],\n       [0.50000014],\n       [0.49998685],\n       [0.49999547],\n       [0.49999962],\n       [0.4999917 ],\n       [0.50000014],\n       [0.50000012],\n       [0.49999291],\n       [0.49999118],\n       [0.50000025],\n       [0.50000016],\n       [0.50000014],\n       [0.50000006],\n       [0.49999941],\n       [0.50000012],\n       [0.49999445],\n       [0.49999788],\n       [0.50000002],\n       [0.49999994],\n       [0.49999234]])"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_breast.predict(dataset= train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126, 6)\n",
      "(83, 6)\n"
     ]
    }
   ],
   "source": [
    "#Constr√≥i um modelo de redes neuronais adequado ao dataset cpu.csv\n",
    "cpu_dataset = read_csv('../datasets/cpu.csv', features=True, label=True)\n",
    "cpu_dataset.X = StandardScaler().fit_transform(cpu_dataset.X)\n",
    "\n",
    "train_dataset, test_dataset = train_test_split(cpu_dataset, test_size=0.4)\n",
    "print(train_dataset.shape())\n",
    "print(test_dataset.shape())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "layer1 = Dense(input_size=6, output_size=6)\n",
    "layer2 = Dense(input_size=6, output_size=4)\n",
    "layer3 = Dense(input_size=4, output_size=1)\n",
    "\n",
    "layer1_act = ReLUActivation()\n",
    "layer2_act = ReLUActivation()\n",
    "layer3_act = SigmoidActivation()\n",
    "\n",
    "model_cpu = NN(\n",
    "    layers=[layer1, layer1_act, layer2, layer2_act, layer3, layer3_act], loss=cross_entropy, loss_derivative=cross_entropy_derivative, verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_cpu.fit(dataset= train_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.50000002],\n       [0.50000006],\n       [0.50000019],\n       [0.50000259],\n       [0.5       ],\n       [0.50000003],\n       [0.50000097],\n       [0.5       ],\n       [0.5       ],\n       [0.50000011],\n       [0.5       ],\n       [0.50000006],\n       [0.5       ],\n       [0.5       ],\n       [0.50000112],\n       [0.5       ],\n       [0.5       ],\n       [0.50000127],\n       [0.49999927],\n       [0.50000012],\n       [0.5       ],\n       [0.49999868],\n       [0.49999761],\n       [0.50000002],\n       [0.5       ],\n       [0.5       ],\n       [0.50000004],\n       [0.4999992 ],\n       [0.49999927],\n       [0.5       ],\n       [0.49999975],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000011],\n       [0.5       ],\n       [0.49999984],\n       [0.49999819],\n       [0.5       ],\n       [0.50000052],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000019],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000261],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000106],\n       [0.49999902],\n       [0.5       ],\n       [0.5       ],\n       [0.50000007],\n       [0.5       ],\n       [0.50000016],\n       [0.5       ],\n       [0.50000003],\n       [0.49999896],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.4999992 ],\n       [0.49999761],\n       [0.50000129],\n       [0.50000011],\n       [0.5       ],\n       [0.5       ],\n       [0.49999937],\n       [0.50000005],\n       [0.5       ],\n       [0.5000001 ],\n       [0.50000112],\n       [0.50000005],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.5       ],\n       [0.50000003],\n       [0.49999725],\n       [0.50000021],\n       [0.50000004],\n       [0.50000117],\n       [0.50000087],\n       [0.5       ],\n       [0.50000005],\n       [0.49999951],\n       [0.50000112],\n       [0.50000004],\n       [0.50000014],\n       [0.5       ],\n       [0.50000112],\n       [0.5       ],\n       [0.5       ],\n       [0.50000002],\n       [0.5       ],\n       [0.5       ],\n       [0.49999484],\n       [0.5       ],\n       [0.50000004],\n       [0.5       ],\n       [0.49999999],\n       [0.49999978],\n       [0.50000167],\n       [0.50000015],\n       [0.50000005],\n       [0.5       ],\n       [0.5       ],\n       [0.49999989],\n       [0.50000027],\n       [0.5       ],\n       [0.49999993],\n       [0.5       ],\n       [0.50000025],\n       [0.50000001],\n       [0.5       ],\n       [0.5       ],\n       [0.50000165]])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cpu.predict(dataset= train_dataset)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-e79b8fed",
   "language": "python",
   "display_name": "PyCharm (sonia)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}